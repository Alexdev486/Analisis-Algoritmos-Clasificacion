# ğŸ“Š ComparaciÃ³n de Algoritmos de ClasificaciÃ³n

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.0+-orange.svg)](https://scikit-learn.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## ğŸ¯ DescripciÃ³n del Proyecto

Este proyecto realiza un **anÃ¡lisis comparativo exhaustivo** de tres algoritmos de clasificaciÃ³n de Machine Learning utilizando el dataset real **Breast Cancer Wisconsin**. El objetivo es evaluar y comparar el rendimiento de diferentes modelos para la detecciÃ³n de tumores malignos y benignos.

### ğŸ“š Algoritmos Evaluados

1. **K-Nearest Neighbors (KNN)** - Clasificador basado en proximidad
2. **Support Vector Machine (SVM)** con kernel RBF - SeparaciÃ³n mediante hiperplanos Ã³ptimos
3. **Random Forest** - Ensemble de Ã¡rboles de decisiÃ³n

## ğŸ”¬ Dataset

**Breast Cancer Wisconsin (Diagnostic Dataset)**
- ğŸ”¢ **569 muestras** de tumores de mama
- ğŸ“Š **30 caracterÃ­sticas numÃ©ricas** extraÃ­das de imÃ¡genes digitalizadas
- ğŸ¯ **ClasificaciÃ³n binaria:**
  - `0` = Maligno (canceroso)
  - `1` = Benigno (no canceroso)

## ğŸš€ CaracterÃ­sticas del AnÃ¡lisis

### âœ¨ Preprocesamiento
- EstandarizaciÃ³n de caracterÃ­sticas con `StandardScaler`
- ReducciÃ³n dimensional con PCA (2 componentes) para visualizaciÃ³n
- DivisiÃ³n estratificada: 75% entrenamiento / 25% prueba

### ğŸ“ˆ MÃ©tricas de EvaluaciÃ³n
- **Accuracy** - PrecisiÃ³n general del modelo
- **Precision** - Exactitud de predicciones positivas
- **Recall** - Sensibilidad del modelo
- **F1-Score** - Media armÃ³nica entre precision y recall
- **AUC-ROC** - Capacidad de discriminaciÃ³n del modelo

### ğŸ“Š Visualizaciones
- âœ… Fronteras de decisiÃ³n en espacio 2D (PCA)
- âœ… Curvas ROC comparativas
- âœ… Matrices de confusiÃ³n detalladas
- âœ… Reportes de clasificaciÃ³n completos

## ğŸ› ï¸ InstalaciÃ³n y Uso

### Requisitos Previos

```bash
Python 3.8 o superior
```

### 1. Clonar el repositorio

```bash
git clone https://github.com/tu-usuario/comparacion-algoritmos.git
cd comparacion-algoritmos
```

### 2. Instalar dependencias

```bash
pip install -r requirements.txt
```

O instalar manualmente:

```bash
pip install scikit-learn pandas matplotlib seaborn jupyter
```

### 3. Ejecutar el notebook

```bash
jupyter notebook ComparaciÃ³n_de_Algoritmos.ipynb
```

O usar JupyterLab:

```bash
jupyter lab ComparaciÃ³n_de_Algoritmos.ipynb
```

## ğŸ“‚ Estructura del Proyecto

```
comparacion-algoritmos/
â”‚
â”œâ”€â”€ ComparaciÃ³n_de_Algoritmos.ipynb  # Notebook principal con todo el anÃ¡lisis
â”œâ”€â”€ README.md                         # DocumentaciÃ³n del proyecto
â”œâ”€â”€ requirements.txt                  # Dependencias del proyecto
â””â”€â”€ .gitignore                        # Archivos ignorados por Git
```

## ğŸ“ Secciones del Notebook

El notebook estÃ¡ organizado en **11 secciones** profesionales:

1. **InstalaciÃ³n de Dependencias e Importaciones**
2. **Carga y ExploraciÃ³n del Dataset**
3. **Preprocesamiento y ReducciÃ³n Dimensional**
4. **DivisiÃ³n de Datos: Entrenamiento y Prueba**
5. **DefiniciÃ³n de Modelos**
6. **Entrenamiento y EvaluaciÃ³n de Modelos**
7. **ComparaciÃ³n de MÃ©tricas**
8. **VisualizaciÃ³n de Fronteras de DecisiÃ³n**
9. **Curvas ROC**
10. **Matrices de ConfusiÃ³n y Reportes Detallados**
11. **Conclusiones y Recomendaciones**

Cada secciÃ³n incluye:
- ğŸ“ Celdas Markdown explicativas con contexto y teorÃ­a
- ğŸ’» CÃ³digo Python limpio y bien documentado
- ğŸ“Š Visualizaciones profesionales
- âœ… Salidas interpretadas

## ğŸ† Resultados Esperados

El notebook genera automÃ¡ticamente:

- **Tabla comparativa** con todas las mÃ©tricas de rendimiento
- **IdentificaciÃ³n del mejor modelo** segÃºn AUC
- **Visualizaciones interactivas** de fronteras de decisiÃ³n
- **AnÃ¡lisis detallado** con matrices de confusiÃ³n
- **Recomendaciones** para mejoras futuras

## âš ï¸ Limitaciones y Consideraciones

- La reducciÃ³n a 2 componentes PCA se realiza Ãºnicamente para **visualizaciÃ³n**
- No se incluye ajuste de hiperparÃ¡metros (Grid Search)
- Para producciÃ³n, se recomienda entrenar con las 30 caracterÃ­sticas originales
- Los falsos negativos son crÃ­ticos en aplicaciones mÃ©dicas

## ğŸ”® Mejoras Futuras

- [ ] Implementar validaciÃ³n cruzada (K-Fold Cross-Validation)
- [ ] OptimizaciÃ³n de hiperparÃ¡metros con GridSearch/RandomSearch
- [ ] Evaluar modelos adicionales (XGBoost, Neural Networks)
- [ ] AnÃ¡lisis de importancia de caracterÃ­sticas
- [ ] Implementar tÃ©cnicas de balanceo de clases
- [ ] Despliegue del mejor modelo con Flask/FastAPI

## ğŸ“ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

## ğŸ“š Referencias

- [Scikit-learn Documentation](https://scikit-learn.org/stable/)
- [Breast Cancer Wisconsin Dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html)
- [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic))

## ğŸ™ Agradecimientos

- Dataset proporcionado por UCI Machine Learning Repository
- Comunidad de scikit-learn
- Recursos educativos de Machine Learning

---

â­ Si este proyecto te fue Ãºtil, considera darle una estrella en GitHub!

**Desarrollado con â¤ï¸ para la comunidad de Machine Learning**

